\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

%\section{Elección del proyecto}


\section{Problema encontrado y propuesta de solución}
Como se ha podido observar en \ref{sec:lol-conceptos}, para cualquier persona que quiera empezar a jugar, existe una cantidad de información abrumadora que puede impedir disfrutar de la experiencia y crear frustaciones.

En primer lugar el gran número de campeones y sus habilidades hace que se tarde tiempo en aprender cómo manejar a los personajes. La siguiente dificultar es encontrar la mejor de combiación de objetos para cada campeón de forma que su utilidad dentro de la partida se maximice. Por último, al disponer de un espacio limitado en el inventario la toma de decisión de que objetos comprar se complica.

Por estas razones, y sabiendo qué jugadores son los que mayor habilidad desmuestran en el juego gracias al sistema de ligas, se puede analizar el comportamiento de estos jugadores para obtener el conocimiento que poseen sobre el juego y ponerlo a disposición de los recién llegados.

Para ello se propone un sistema que sea capaz de analizar las partidas de los jugadores de más alto nivel y extraer el conocimiento que poseen. Este conocimiento será puesto a disposición de otros jugadores por medio de una aplicación web.

Para realizar el análisis de partidas se va a usar aprendizaje no supervisado, en concreto algoritmos para la obtención de conjuntos de elementos frecuentes. Al partir de los datos de los jugadores de mayor habilidad, de forma indirecta, se debería obtener el conjunto de objetos más útil para cada campeón.

\section{Desarrollo de \textit{notebooks} y web}
El desarrollo del proyecto ha tenido dos fases fácilmente diferenciadas, desarrollo de \textit{notebooks} y desarrollo de la aplicación web. A pesar de que pueda parecer que se ha hecho el mismo trabajo dos veces, esta metodología ha aportado grandes ventajas a lo largo del trabajo.

En primer lugar, el uso de \textit{notebooks} ha permitido realizar pruebas de forma rápida con la API y poder comprobar de forma ágil que los datos necesarios para el desarrollo estaban accesibles, al igual que, ya teniendo muestras de los datos, realizar varias ejecuciones de los algoritmos candidatos y evaluar sus resultados.

En segundo lugar, al poder ejecutar fragmentos de código aislados se han podido identificar y solucionar varios problemas en la \textit{pipeline} (\ref{sec:rate-limit} y \ref{sec:fault-tolerance}) de forma rápida y sin que afecte al resto del desarrollo.

Por último, esta forma de gestionar el desarrollo ha permitido que el desarrollo de la \textit{pipeline} integrada en la aplicación haya sido muy ágil. Además de que, como la mayoría de problemas se habían identificado en los \textit{notebooks}, el proceso final dentro la aplicación ha estado libre, casi al completo, de errores.

\section{Control de velocidad de peticiones por ratios de la API}\label{sec:rate-limit}
Al depender de una API externa para realizar la recopilación de datos, las fases que dependen de la misma tienen un límite máximo de peticiones por tiempo\footnote{\url{https://developer.riotgames.com/docs/portal\#web-apis_api-keys}} que hay que respetar, ya que demasiadas violaciones de los límites pueden provocar que la desarrolladora restrinja el acceso a los datos. Para el tipo de clave de acceso que se tiene actualmente (clave personal) los límites son:
\begin{itemize}
	\tightlist
	\item 20 peticiones por segundo
	\item 100 peticiones cada dos minutos
\end{itemize}
Al inicio del desarrollo se decidió usar retroceso exponencial. Esto es ir aumentando un tiempo de retardo entre peticiones introducido de forma manual cuando una petición falla, e ir disminuyéndolo poco a poco cuando el servidor vuelve a responder correctamente. Sin embargo el tiempo de espera que este método introducía disminuía notablemente el rendimiento de la extracción de datos, alargando el proceso más de lo necesario, además de añadir complejidad al proceso.

Más adelante se localizó en la documentación de la API que, cuando una petición se rechaza por haber sobrepasado el límite, la respuesta de esa petición fallida retornaba en una cabecera el tiempo de espera necesario para volver a obtener respuestas correctas.

Se procedió a cambiar el restroceso exponencial por una espera única del tiempo indicado en la respuesta, haciendo que el proceso de recopilación fuera más limpio y minimizando las esperas, de tal forma que se pudo aumentar el ratio de obtención de datos.

\section{Tolerancia y recuperación de fallos}\label{sec:fault-tolerance}
Como se ha explicado en la sección anterior (\ref{sec:rate-limit}), la recopilación de datos ha sido temporalmente costoso. En el caso de que ocurriera un error mientras se ejecutase, el proceso empezaría de cero y se pedirían datos que ya estuvieran guardados, perdiendo tiempo valioso.

Por ello, desde el inicio del proyecto se decidió que el sistema tendría que contar con medios para que, en caso de fallos imprevistos, el proceso debería ser capaz de continuar la ejecución como si no hubiera ocurrido ningún fallo.

Para lograr el objetivo propuesto se guarda de forma periódica el estado de ejecución, serializando múltiples variables de control. En caso de que el proceso se detenga el estado previo de ejecución está guardado. Ahora, una vez reiniciada la ejecución, las variables que han sido guardadas previamente no se declaran como variables normales, si no que se comprueba si existe una serialización para ellas, en caso afirmativo se cargan y la ejecución contunúa a partir del punto cargado. En caso de que no exista un estado guardado, se asigna un valor inicial a las variables y el proceso empezaría de cero.

\section{Proceso de recopilación y entrenamiento}
En esta sección se va a explicar las fases del proceso de recopilación de datos y cómo ha llevado a cabo la recopilación de los mismos, además de su transformación y entrenamiento final.

\subsection{Extracción jugadores}
\subsection{Extracción de partidas}
\subsection{Añadir posición}
\subsection{Generar transacciones}
\subsection{Generar conjuntos frecuentes}


\section{Elección del algoritmo}
Como se ha comentado anteriormente, para la resolución del problema se va a usar un algoritmo para obtención de conjuntos de elementos frecuentes.

El listado de algoritmos\cite{chee_jaafar_aziz_hasan_yeoh_2018} que son capaces de resolver este problema es extenso, sin embargo, por tener conocimiento previo tanto del Apriori, como del FP-Growth al haber sido tratados durante el máster, se ha optado por acotar la decisión a estos. Adicionalmente, estos son los que generalmente suelen recomendarse y los que se encuentran implementados en varias bibliotecas de aprendizaje automático.

En base a artículos existentes\cite{chonyy_2020_apriori}\cite{chonyy_2020_fpgrowth} se decidió usar FP-Growth en vez del Apriori por ser más rápido y requerir menos memoria. Por lo que durante el desarrollo del proyecto se usó ese algoritmo en las pruebas iniciales y después de realizar la recopilación de datos.

Sin embargo, con los datos finales ocurría que el Apriori finalizaba su ejecución más rápido con el FP-Growth, por lo que finalmente se ha decidido dejar este algoritmo como el definitivo para la generación de conjuntos frecuentes.
